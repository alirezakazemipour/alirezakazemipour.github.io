

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>The law of total variance in practice - Alireza Kazemipour</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Alireza Kazemipour">
<meta property="og:title" content="The law of total variance in practice">


  <link rel="canonical" href="https://alirezakazemipour.github.io/posts/2025/08/ltv/">
  <meta property="og:url" content="https://alirezakazemipour.github.io/posts/2025/08/ltv/">



  <meta property="og:description" content="In this post, I‚Äôll solve an example that requires the use the law of total variance in RL.BackgroundBackground on some technical tools used in the main section.  Before we start, note that for two random variables $X\, \mathrm{and}\, Y$, $\mathbb{E}[Y \mid X]$ is a shorthand notation for $\mathbb{E}[Y \mid \sigma(X)]$!The law of total varianceLet $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $\mathcal{G}_1 \subseteq \mathcal{G}_2 \subseteq \mathcal{F}$ two sub-$\sigma$-algebras of $\mathcal{F}$, $X$ an integrable random variable on $(\Omega, \mathcal{F}, \mathbb{P})$  with finite variance. The following holds true:\(\mathbb{V}(X \mid \mathcal{G}_1) = \mathbb{\mathbb{E}}[\mathbb{V}(X \mid \mathcal{G}_2) \mid \mathcal{G}_1] - \mathbb{\mathbb{V}}[\mathbb{E}(X \mid \mathcal{G}_2) \mid \mathcal{G}_1].\)The law of the unconscious statistician (LOTUS)Let $\mathbb{P}_X$ be the pushforward of the random element $X \in \mathcal{X}$. For any real-valued, $f: \mathcal{X} \to \mathbb{R}$ measurable function,[\mathbb{E}[f(X)] = \sum_xf(x)\mathbb{P}_X(x),]or[\mathbb{E}[f(X)] = \int_\mathcal{X} f(x)\mathrm{d}\mathbb{P}_X(x),]provided that either the right-hand side, or the left-hand side exist. This is known as the ‚Äúlaw  of  the  unconscious  statistician‚Äù, or LOTUS.Jensen‚Äôs inequalityLet $\bar{\mathbb{R}} = \mathbb{R} \cup$ 2025-08-19-ltv.md2025-08-19-ltv.md{$ -\infty, +\infty$}, and $\mathrm{dom}(f) = {x \in \mathbb{R}^d: f(x) &lt; \infty }$ for a real-valued function $f$ on $\mathbb{R}^d$.Jensen‚Äôs inequality: Let $f: \mathbb{R}^d \to \bar{\mathbb{R}}$ be a measurable convex function and $X$ be an $\mathbb{R}^d$-valued random element on some probability space such that $\mathbb{E}[X]$ exists and $X \in \mathrm{dom}(f)$ holds almost surely. Then,[\mathbb{E}[f(X)] \geq f(\mathbb{E}[X]).]An example the law of total variance in practiceWe want to compare the variance of the target for SARSA and expected SARSA. The update rule of is[Q_{t + 1}(S_t, A_t) = Q_t(S_t, A_t) + \alpha \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) - Q_t(S_t, A_t) \right].]And the update rule for expected SARSA is[Q_{t + 1}(S_t, A_t) = Q_t(S_t, A_t) + \alpha \left[R_{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) - Q_t(S_t, A_t) \right],]where $\pi$ is the fixed policy that was used to generate the data $S_0, A_0, R_1, \, \dots\;$.Let $H_t = (S_0, A_0, R_1, \dots, S_t)$, and $H‚Äô_t = (S_0, A_0, R_1, \dots, S_t, A_t)$.  Show that[\mathbb{V}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H_{t + 1}\right] \geq \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H_{t + 1}\right].]First, note that using Markov property, we can replace $H_{t + 1}$ in the above expressions with $S_{t + 1}$. Second,[\mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert S_{t + 1}\right] = 0.]Because given $S_{t + 1}$ (it is not random anymore), the randomness in the actions is averaged out using the expectation, so there is no randomness remaining more. Third,[\begin{align}\mathbb{V}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1}\right] &amp; = \mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1})^2 \middle\vert S_{t + 1}\right] - \mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1}\right]^2 \quad \text{(def of variance)} \&amp; = \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 - \left(\sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1}) \right)^2 \quad \text{(def of expectation and LOTUS)} \&amp;\geq \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 - \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1})^2 Q_t(a, S_{t + 1})^2 \quad \text{(Cauchy-Swhartz)} \&amp;\geq \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 - \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 \&amp;\geq 0.\end{align}]Right off the bat, we already knew that the variance is always non-negative anyway. üòÖ  When would have the equality happened?Well you‚Äôre asking when the variance of a random variable is zero. Then, the answer is when it‚Äôs deterministic. For a deterministic random variable $X$ we have that $\mathbb{E}[X] = X$. Hence, we want[\mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1}\right] = Q_t(S_{t + 1}, A_{t + 1}),]which can only happen when the policy is deterministic.  Show that[\mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H‚Äôt \right] \geq \mathbb{V}\left[R{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H‚Äô_t\right],]that is, the appropriate conditional variance of the SARSA target is always at least as large as that of for the expected SARSA target.For convenience, let $Z_t = (S_t, A_t)$. We have,[\begin{align}&amp; \mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H‚Äô_t \right] - \mathbb{V}\left[R_{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H‚Äô_t\right] =  \&amp; \mathbb{V} [R_{t + 1} \mid Z_t] + \gamma^2 \mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right] + 2\mathrm{Cov}\left[R_{t + 1},  \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right] - \mathbb{V} [R_{t + 1} \mid Z_t] - \gamma^2 \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert Z_t\right]  - 2\mathrm{Cov}\left[R_{t + 1},  \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right)  \middle\vert Z_t \right]= \&amp; \gamma^2 \mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right] + 2\mathrm{Cov}\left[R_{t + 1},  \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right]  - \gamma^2 \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert Z_t\right]  - 2\mathrm{Cov}\left[R_{t + 1},  \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right)  \middle\vert Z_t \right].\end{align}]For covariance terms, note that although $R_{t + 1}$ is not independent of $Q_t$ but given $Z_t$, it is (it is naturally independent of $S_{t + 1}$ and $A_{t + 1}$). So, covariance terms are zero. Hence, we end up with[\mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H‚Äôt \right] - \mathbb{V}\left[R{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H‚Äôt\right] = \gamma^2 \left(\mathbb{V} \left[Q_t(S{t + 1}, A_{t + 1}) \middle\vert Z_t \right]   - \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert Z_t\right]\right).]Now we apply the law of total variance[\begin{align}&amp;\gamma^2 \left(\mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right]   - \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert Z_t\right]\right) = \&amp;\gamma^2 \left(\mathbb{E}\left[\mathbb{V}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right]   -  \mathbb{V}\left[\mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right] \right) - \&amp;\gamma^2 \left( \mathbb{E}\left[\mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert S_{t + 1}\right] \middle\vert Z_t \right] - \mathbb{V}\left[\mathbb{E}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert S_{t + 1}\right] \middle\vert Z_t \right] \right)\end{align}]First, $\mathbb{E}\left[\mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right] = 0$. Given $S_{t + 1}$ everything inside becomes deterministic. Also,[\mathbb{V}\left[\mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right]  = \mathbb{V}\left[ \sum_{a‚Äô} \pi(a‚Äô \mid S_{t + 1})Q_t(S_{t + 1}, a‚Äô) \middle\vert Z_t \right]= \mathbb{V}\left[\mathbb{E}\left[ \sum_{a‚Äô} \pi(a‚Äô \mid S_{t + 1})Q_t(S_{t + 1}, a‚Äô) \middle\vert S_{t + 1}\right] \middle\vert Z_t \right]]So, we have[\mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H‚Äôt \right] - \mathbb{V}\left[R{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H‚Äôt\right] =  \gamma^2 \mathbb{E}[\mathbb{V}[Q_t(S{t + 1}, A_{t + 1}) \mid S_{t + 1}] \mid Z_t] \geq 0.]Since the variance is always positive.Reference  CMPUT 365: Introduction to Reinforcement Learning,  Worksheet 7.  Bandit Algorithms.">





  

  





  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2025-08-19T00:00:00-07:00">








  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "Alireza Kazemipour",
      "url" : "https://alirezakazemipour.github.io",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="https://alirezakazemipour.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Alireza Kazemipour Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="https://alirezakazemipour.github.io/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="https://alirezakazemipour.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="https://alirezakazemipour.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="https://alirezakazemipour.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="https://alirezakazemipour.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="https://alirezakazemipour.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="https://alirezakazemipour.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="https://alirezakazemipour.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="https://alirezakazemipour.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="https://alirezakazemipour.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="https://alirezakazemipour.github.io/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="https://alirezakazemipour.github.io/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="https://alirezakazemipour.github.io/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="https://alirezakazemipour.github.io/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="https://alirezakazemipour.github.io/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="https://alirezakazemipour.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="https://alirezakazemipour.github.io/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="https://alirezakazemipour.github.io/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="https://alirezakazemipour.github.io/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="https://alirezakazemipour.github.io/">Alireza Kazemipour</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://alirezakazemipour.github.io/misc/">Miscellaneous</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://alirezakazemipour.github.io/unfin/">Unfinished ideas</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://alirezakazemipour.github.io/crs_prjcts/">Course projects</a></li>
          
            
            <li class="masthead__menu-item"><a href="https://alirezakazemipour.github.io/year-archive/">Journal</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  



  <article class="page wide" itemscope itemtype="http://schema.org/CreativeWork">
    <meta itemprop="headline" content="The law of total variance in practice">
    <meta itemprop="description" content="In this post, I‚Äôll solve an example that requires the use the law of total variance in RL.BackgroundBackground on some technical tools used in the main section.  Before we start, note that for two random variables $X\, \mathrm{and}\, Y$, $\mathbb{E}[Y \mid X]$ is a shorthand notation for $\mathbb{E}[Y \mid \sigma(X)]$!The law of total varianceLet $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $\mathcal{G}_1 \subseteq \mathcal{G}_2 \subseteq \mathcal{F}$ two sub-$\sigma$-algebras of $\mathcal{F}$, $X$ an integrable random variable on $(\Omega, \mathcal{F}, \mathbb{P})$  with finite variance. The following holds true:\(\mathbb{V}(X \mid \mathcal{G}_1) = \mathbb{\mathbb{E}}[\mathbb{V}(X \mid \mathcal{G}_2) \mid \mathcal{G}_1] - \mathbb{\mathbb{V}}[\mathbb{E}(X \mid \mathcal{G}_2) \mid \mathcal{G}_1].\)The law of the unconscious statistician (LOTUS)Let $\mathbb{P}_X$ be the pushforward of the random element $X \in \mathcal{X}$. For any real-valued, $f: \mathcal{X} \to \mathbb{R}$ measurable function,[\mathbb{E}[f(X)] = \sum_xf(x)\mathbb{P}_X(x),]or[\mathbb{E}[f(X)] = \int_\mathcal{X} f(x)\mathrm{d}\mathbb{P}_X(x),]provided that either the right-hand side, or the left-hand side exist. This is known as the ‚Äúlaw  of  the  unconscious  statistician‚Äù, or LOTUS.Jensen‚Äôs inequalityLet $\bar{\mathbb{R}} = \mathbb{R} \cup$ 2025-08-19-ltv.md2025-08-19-ltv.md{$ -\infty, +\infty$}, and $\mathrm{dom}(f) = {x \in \mathbb{R}^d: f(x) &lt; \infty }$ for a real-valued function $f$ on $\mathbb{R}^d$.Jensen‚Äôs inequality: Let $f: \mathbb{R}^d \to \bar{\mathbb{R}}$ be a measurable convex function and $X$ be an $\mathbb{R}^d$-valued random element on some probability space such that $\mathbb{E}[X]$ exists and $X \in \mathrm{dom}(f)$ holds almost surely. Then,[\mathbb{E}[f(X)] \geq f(\mathbb{E}[X]).]An example the law of total variance in practiceWe want to compare the variance of the target for SARSA and expected SARSA. The update rule of is[Q_{t + 1}(S_t, A_t) = Q_t(S_t, A_t) + \alpha \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) - Q_t(S_t, A_t) \right].]And the update rule for expected SARSA is[Q_{t + 1}(S_t, A_t) = Q_t(S_t, A_t) + \alpha \left[R_{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) - Q_t(S_t, A_t) \right],]where $\pi$ is the fixed policy that was used to generate the data $S_0, A_0, R_1, \, \dots\;$.Let $H_t = (S_0, A_0, R_1, \dots, S_t)$, and $H‚Äô_t = (S_0, A_0, R_1, \dots, S_t, A_t)$.  Show that[\mathbb{V}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H_{t + 1}\right] \geq \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H_{t + 1}\right].]First, note that using Markov property, we can replace $H_{t + 1}$ in the above expressions with $S_{t + 1}$. Second,[\mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert S_{t + 1}\right] = 0.]Because given $S_{t + 1}$ (it is not random anymore), the randomness in the actions is averaged out using the expectation, so there is no randomness remaining more. Third,[\begin{align}\mathbb{V}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1}\right] &amp; = \mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1})^2 \middle\vert S_{t + 1}\right] - \mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1}\right]^2 \quad \text{(def of variance)} \&amp; = \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 - \left(\sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1}) \right)^2 \quad \text{(def of expectation and LOTUS)} \&amp;\geq \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 - \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1})^2 Q_t(a, S_{t + 1})^2 \quad \text{(Cauchy-Swhartz)} \&amp;\geq \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 - \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 \&amp;\geq 0.\end{align}]Right off the bat, we already knew that the variance is always non-negative anyway. üòÖ  When would have the equality happened?Well you‚Äôre asking when the variance of a random variable is zero. Then, the answer is when it‚Äôs deterministic. For a deterministic random variable $X$ we have that $\mathbb{E}[X] = X$. Hence, we want[\mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1}\right] = Q_t(S_{t + 1}, A_{t + 1}),]which can only happen when the policy is deterministic.  Show that[\mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H‚Äôt \right] \geq \mathbb{V}\left[R{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H‚Äô_t\right],]that is, the appropriate conditional variance of the SARSA target is always at least as large as that of for the expected SARSA target.For convenience, let $Z_t = (S_t, A_t)$. We have,[\begin{align}&amp; \mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H‚Äô_t \right] - \mathbb{V}\left[R_{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H‚Äô_t\right] =  \&amp; \mathbb{V} [R_{t + 1} \mid Z_t] + \gamma^2 \mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right] + 2\mathrm{Cov}\left[R_{t + 1},  \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right] - \mathbb{V} [R_{t + 1} \mid Z_t] - \gamma^2 \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert Z_t\right]  - 2\mathrm{Cov}\left[R_{t + 1},  \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right)  \middle\vert Z_t \right]= \&amp; \gamma^2 \mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right] + 2\mathrm{Cov}\left[R_{t + 1},  \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right]  - \gamma^2 \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert Z_t\right]  - 2\mathrm{Cov}\left[R_{t + 1},  \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right)  \middle\vert Z_t \right].\end{align}]For covariance terms, note that although $R_{t + 1}$ is not independent of $Q_t$ but given $Z_t$, it is (it is naturally independent of $S_{t + 1}$ and $A_{t + 1}$). So, covariance terms are zero. Hence, we end up with[\mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H‚Äôt \right] - \mathbb{V}\left[R{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H‚Äôt\right] = \gamma^2 \left(\mathbb{V} \left[Q_t(S{t + 1}, A_{t + 1}) \middle\vert Z_t \right]   - \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert Z_t\right]\right).]Now we apply the law of total variance[\begin{align}&amp;\gamma^2 \left(\mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right]   - \mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert Z_t\right]\right) = \&amp;\gamma^2 \left(\mathbb{E}\left[\mathbb{V}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right]   -  \mathbb{V}\left[\mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right] \right) - \&amp;\gamma^2 \left( \mathbb{E}\left[\mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert S_{t + 1}\right] \middle\vert Z_t \right] - \mathbb{V}\left[\mathbb{E}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert S_{t + 1}\right] \middle\vert Z_t \right] \right)\end{align}]First, $\mathbb{E}\left[\mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right] = 0$. Given $S_{t + 1}$ everything inside becomes deterministic. Also,[\mathbb{V}\left[\mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right]  = \mathbb{V}\left[ \sum_{a‚Äô} \pi(a‚Äô \mid S_{t + 1})Q_t(S_{t + 1}, a‚Äô) \middle\vert Z_t \right]= \mathbb{V}\left[\mathbb{E}\left[ \sum_{a‚Äô} \pi(a‚Äô \mid S_{t + 1})Q_t(S_{t + 1}, a‚Äô) \middle\vert S_{t + 1}\right] \middle\vert Z_t \right]]So, we have[\mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H‚Äôt \right] - \mathbb{V}\left[R{t + 1} + \gamma \sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert H‚Äôt\right] =  \gamma^2 \mathbb{E}[\mathbb{V}[Q_t(S{t + 1}, A_{t + 1}) \mid S_{t + 1}] \mid Z_t] \geq 0.]Since the variance is always positive.Reference  CMPUT 365: Introduction to Reinforcement Learning,  Worksheet 7.  Bandit Algorithms.">
    <meta itemprop="datePublished" content="August 19, 2025">
    

    <div class="page__inner-wrap">
      
        <header>
          <h1 class="page__title" itemprop="headline">The law of total variance in practice
</h1>
          
            <p class="page__meta"><i class="fa fa-clock-o" aria-hidden="true"></i> 


  
	  8 minute read
	
</p>
          
        
        
        
          <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2025-08-19T00:00:00-07:00">August 19, 2025</time></p>
        
        
             
        
    
        </header>
      

      <section class="page__content" itemprop="text">
        <p>In this post, I‚Äôll solve an example that requires the use the law of total variance in RL.</p>

<h1 id="background">Background</h1>
<p>Background on some technical tools used in the main section.  Before we start, note that for two random variables $X\, \mathrm{and}\, Y$, $\mathbb{E}[Y \mid X]$ is a shorthand notation for $\mathbb{E}[Y \mid \sigma(X)]$!</p>

<h2 id="the-law-of-total-variance">The law of total variance</h2>
<p>Let $(\Omega, \mathcal{F}, \mathbb{P})$ be a probability space, $\mathcal{G}_1 \subseteq \mathcal{G}_2 \subseteq \mathcal{F}$ two sub-$\sigma$-algebras of $\mathcal{F}$, $X$ an integrable random variable on $(\Omega, \mathcal{F}, \mathbb{P})$  with finite variance. The following holds true:</p>

<p>\(\mathbb{V}(X \mid \mathcal{G}_1) = \mathbb{\mathbb{E}}[\mathbb{V}(X \mid \mathcal{G}_2) \mid \mathcal{G}_1] - \mathbb{\mathbb{V}}[\mathbb{E}(X \mid \mathcal{G}_2) \mid \mathcal{G}_1].\)</p>
<h2 id="the-law-of-the-unconscious-statistician-lotus">The law of the unconscious statistician (LOTUS)</h2>
<p>Let $\mathbb{P}_X$ be the pushforward of the random element $X \in \mathcal{X}$. For any real-valued, $f: \mathcal{X} \to \mathbb{R}$ measurable function,</p>

\[\mathbb{E}[f(X)] = \sum_xf(x)\mathbb{P}_X(x),\]

<p>or</p>

\[\mathbb{E}[f(X)] = \int_\mathcal{X} f(x)\mathrm{d}\mathbb{P}_X(x),\]

<p>provided that either the right-hand side, or the left-hand side exist. This is known as the ‚Äúlaw  of  the  unconscious  statistician‚Äù, or LOTUS.</p>

<h2 id="jensens-inequality">Jensen‚Äôs inequality</h2>

<p>Let $\bar{\mathbb{R}} = \mathbb{R} \cup$ <a href="2025-08-19-ltv.md">2025-08-19-ltv.md</a><a href="2025-08-19-ltv.md">2025-08-19-ltv.md</a>{$ -\infty, +\infty$}, and $\mathrm{dom}(f) = {x \in \mathbb{R}^d: f(x) &lt; \infty }$ for a real-valued function $f$ on $\mathbb{R}^d$.</p>

<p><em>Jensen‚Äôs inequality</em>: Let $f: \mathbb{R}^d \to \bar{\mathbb{R}}$ be a measurable convex function and $X$ be an $\mathbb{R}^d$-valued random element on some probability space such that $\mathbb{E}[X]$ exists and $X \in \mathrm{dom}(f)$ holds almost surely. Then,</p>

\[\mathbb{E}[f(X)] \geq f(\mathbb{E}[X]).\]

<h1 id="an-example-the-law-of-total-variance-in-practice">An example the law of total variance in practice</h1>
<p>We want to compare the variance of the target for SARSA and expected SARSA. The update rule of is</p>

\[Q_{t + 1}(S_t, A_t) = Q_t(S_t, A_t) + \alpha \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) - Q_t(S_t, A_t) \right].\]

<p>And the update rule for expected SARSA is</p>

\[Q_{t + 1}(S_t, A_t) = Q_t(S_t, A_t) + \alpha \left[R_{t + 1} + \gamma \sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) - Q_t(S_t, A_t) \right],\]

<p>where $\pi$ is the fixed policy that was used to generate the data $S_0, A_0, R_1, \, \dots\;$.</p>

<p>Let $H_t = (S_0, A_0, R_1, \dots, S_t)$, and $H‚Äô_t = (S_0, A_0, R_1, \dots, S_t, A_t)$.</p>

<ol>
  <li>Show that</li>
</ol>

\[\mathbb{V}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H_{t + 1}\right] \geq \mathbb{V}\left[\sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert H_{t + 1}\right].\]

<p>First, note that using Markov property, we can replace $H_{t + 1}$ in the above expressions with $S_{t + 1}$. Second,</p>

\[\mathbb{V}\left[\sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert S_{t + 1}\right] = 0.\]

<p>Because given $S_{t + 1}$ (it is not random anymore), the randomness in the actions is averaged out using the expectation, so there is no randomness remaining more. Third,</p>

\[\begin{align*}  
\mathbb{V}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1}\right] &amp; = \mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1})^2 \middle\vert S_{t + 1}\right] - \mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1}\right]^2 \quad \text{(def of variance)} \\  
&amp; = \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 - \left(\sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1}) \right)^2 \quad \text{(def of expectation and LOTUS)} \\  
&amp;\geq \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 - \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1})^2 Q_t(a, S_{t + 1})^2 \quad \text{(Cauchy-Swhartz)} \\  
&amp;\geq \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 - \sum_{a \in \mathcal{A}} \pi(a \mid S_{t + 1}) Q_t(a, S_{t + 1})^2 \\  
&amp;\geq 0.  
\end{align*}\]

<p>Right off the bat, we already knew that the variance is always non-negative anyway. üòÖ</p>
<ol>
  <li>When would have the equality happened?</li>
</ol>

<p>Well you‚Äôre asking when the variance of a random variable is zero. Then, the answer is when it‚Äôs deterministic. For a deterministic random variable $X$ we have that $\mathbb{E}[X] = X$. Hence, we want</p>

\[\mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1}\right] = Q_t(S_{t + 1}, A_{t + 1}),\]

<p>which can only happen when the policy is deterministic.</p>

<ol>
  <li>Show that</li>
</ol>

\[\mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H'_t \right] \geq \mathbb{V}\left[R_{t + 1} + \gamma \sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert H'_t\right],\]

<p>that is, the appropriate conditional variance of the SARSA target is always at least as large as that of for the expected SARSA target.</p>

<p>For convenience, let $Z_t = (S_t, A_t)$. We have,</p>

\[\begin{align*}  
&amp; \mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H'_t \right] - \mathbb{V}\left[R_{t + 1} + \gamma \sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert H'_t\right] =  \\  
&amp; \mathbb{V} [R_{t + 1} \mid Z_t] + \gamma^2 \mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right] + 2\mathrm{Cov}\left[R_{t + 1},  \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right] - \mathbb{V} [R_{t + 1} \mid Z_t] - \gamma^2 \mathbb{V}\left[\sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert Z_t\right]  - 2\mathrm{Cov}\left[R_{t + 1},  \gamma \sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right)  \middle\vert Z_t \right]= \\  
&amp; \gamma^2 \mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right] + 2\mathrm{Cov}\left[R_{t + 1},  \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right]  - \gamma^2 \mathbb{V}\left[\sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert Z_t\right]  - 2\mathrm{Cov}\left[R_{t + 1},  \gamma \sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right)  \middle\vert Z_t \right].  
\end{align*}\]

<p>For covariance terms, note that although $R_{t + 1}$ is not independent of $Q_t$ but given $Z_t$, it is (it is naturally independent of $S_{t + 1}$ and $A_{t + 1}$). So, covariance terms are zero. Hence, we end up with</p>

\[\mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H'_t \right] - \mathbb{V}\left[R_{t + 1} + \gamma \sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert H'_t\right] =   
\gamma^2 \left(\mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right]   - \mathbb{V}\left[\sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert Z_t\right]\right).\]

<p>Now we apply the law of total variance</p>

\[\begin{align*}  
&amp;\gamma^2 \left(\mathbb{V} \left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert Z_t \right]   - \mathbb{V}\left[\sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert Z_t\right]\right) = \\  
&amp;\gamma^2 \left(\mathbb{E}\left[\mathbb{V}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right]   -  \mathbb{V}\left[\mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right] \right) - \\  
&amp;\gamma^2 \left( \mathbb{E}\left[\mathbb{V}\left[\sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert S_{t + 1}\right] \middle\vert Z_t \right] - \mathbb{V}\left[\mathbb{E}\left[\sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert S_{t + 1}\right] \middle\vert Z_t \right] \right)  
\end{align*}\]

<p>First, $\mathbb{E}\left[\mathbb{V}\left[\sum_{a‚Äô \in \mathcal{A}} \pi\left(a‚Äô \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a‚Äô \right) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right] = 0$. Given $S_{t + 1}$ everything inside becomes deterministic. Also,</p>

\[\mathbb{V}\left[\mathbb{E}\left[Q_t(S_{t + 1}, A_{t + 1}) \middle\vert S_{t + 1} \right] \middle\vert Z_t \right]  = \mathbb{V}\left[ \sum_{a'} \pi(a' \mid S_{t + 1})Q_t(S_{t + 1}, a') \middle\vert Z_t \right]= \mathbb{V}\left[\mathbb{E}\left[ \sum_{a'} \pi(a' \mid S_{t + 1})Q_t(S_{t + 1}, a') \middle\vert S_{t + 1}\right] \middle\vert Z_t \right]\]

<p>So, we have</p>

\[\mathbb{V} \left[R_{t + 1} + \gamma Q_t(S_{t + 1}, A_{t + 1}) \middle\vert H'_t \right] - \mathbb{V}\left[R_{t + 1} + \gamma \sum_{a' \in \mathcal{A}} \pi\left(a' \mid S_{t + 1}\right)Q_t \left(S_{t + 1}, a' \right) \middle\vert H'_t\right] =  \gamma^2 \mathbb{E}[\mathbb{V}[Q_t(S_{t + 1}, A_{t + 1}) \mid S_{t + 1}] \mid Z_t] \geq 0.\]

<p>Since the variance is always positive.</p>

<h1 id="reference">Reference</h1>

<ul>
  <li><a href="https://szepi.github.io/cmput-365-w25/">CMPUT 365: Introduction to Reinforcement Learning</a>,  <a href="https://szepi.github.io/cmput-365-w25/documents/worksheets/w7_soln.pdf">Worksheet 7</a>.</li>
  <li><a href="https://sites.ualberta.ca/~szepesva/books.html">Bandit Algorithms</a>.</li>
</ul>

        
      </section>

      <footer class="page__meta">
        
        


  




  
  
  

  <p class="page__taxonomy">
    <strong><i class="fa fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
    <span itemprop="keywords">
    
      
      
      <a href="https://alirezakazemipour.github.io/tags/#learning" class="page__taxonomy-item" rel="tag">learning</a>
    
    </span>
  </p>




      </footer>

      

      


  <nav class="pagination">
    
      <a href="https://alirezakazemipour.github.io/posts/2025/08/sblv/" class="pagination--pager" title="Sobolev spaces (not too wiggly functions), Hilbert spaces, and RHKS
">Previous</a>
    
    
      <a href="https://alirezakazemipour.github.io/posts/2025/09/stchstc-apprxmtn-1/" class="pagination--pager" title="Stochastic Approximation Part 1
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/alirezakazemipour"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <!-- <li><a href="https://alirezakazemipour.github.io/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li> -->
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2025 Alireza Kazemipour. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="https://alirezakazemipour.github.io/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

